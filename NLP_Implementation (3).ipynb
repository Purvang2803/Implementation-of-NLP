{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2290179f-4c8a-4cdc-9ec1-1e0a800a3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim.models import Word2Vec,FastText\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe7bc733-5575-43ef-8f1e-5771c0447db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:/Users/DELL8/AppData/Roaming/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"C:/Users/DELL8/AppData/Roaming/nltk_data\")\n",
    "nltk.download('punkt', download_dir=\"C:/Users/DELL8/AppData/Roaming/nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "af66615f-2376-4ae3-893d-9123dba4d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\DELL8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\DELL8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4be0bf-15a2-4e06-8941-5110599c57fb",
   "metadata": {},
   "source": [
    "#### READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e056bfc0-9e4b-4ea4-abe2-63b7e6c2a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path\n",
    "file_path = \"D:\\wiki file\\enwiki-latest-abstract3.xml\"\n",
    "\n",
    "text_data = []\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for _ in range(10000):  \n",
    "        text_data.append(file.readline().strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3624f-f3b0-47f4-80a5-ea1ceccd9b29",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1178a34a-432d-4453-9621-272fd76d8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "clean_text = re.sub(r\"<.*?>\", \" \", raw_text)  \n",
    "clean_text = re.sub(r\"https?://\\S+\", \" \", clean_text) \n",
    "clean_text = re.sub(r\"[^a-zA-Z\\s]\", \" \", clean_text)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e4dfc21-b8df-4995-8523-899ba6202138",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bdd37f5f-b456-4eee-a61b-709b6639a353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text (First 500 chars):      Wikipedia  Diego Maradona stadium       Diego Maradona stadium can refer to       All article disambiguation pages        All disambiguation pages        Place name disambiguation pages        Short description is different from Wikidata             Wikipedia  White Stone       White Stone may refer to       See also             Wikipedia  Yes Tor         grid ref UK   SX            In popular culture        References        External links             Wikipedia  Watermelon Man  composition\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Raw Text (First 500 chars):\", clean_text[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eaed38-9ad5-420c-9feb-8ca1f24f5ce6",
   "metadata": {},
   "source": [
    "#### lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7fa57f16-44b0-4b6a-b9a0-2ef82fa1be04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Text (First 500 chars): Wikipedia Diego Maradona stadium Diego Maradona stadium can refer to All article disambiguation page All disambiguation page Place name disambiguation page Short description is different from Wikidata Wikipedia White Stone White Stone may refer to See also Wikipedia Yes Tor grid ref UK SX In popular culture References External link Wikipedia Watermelon Man composition length Herbie Hancock version Mongo Santamar a version Chart performance Herbie Hancock version Other version Samples Personnel R\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_text = \" \".join([lemmatizer.lemmatize(word) for word in clean_text.split()])\n",
    "\n",
    "print(\"Lemmatized Text (First 500 chars):\", lemmatized_text[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161c3f5-f32e-4590-a3e5-9520f1978558",
   "metadata": {},
   "source": [
    "#### count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "206065b2-5c6b-4613-a004-d5ccfe995b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer (First 10 features): ['abort' 'about' 'access' 'accessdate' 'account' 'acid' 'act' 'active'\n",
      " 'addison' 'additional']\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(max_features=10000)\n",
    "count_vectors = count_vectorizer.fit_transform([lemmatized_text])\n",
    "\n",
    "print(\"Count Vectorizer (First 10 features):\", count_vectorizer.get_feature_names_out()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d445851c-3f1b-4513-8925-2ed27f86197d",
   "metadata": {},
   "source": [
    "#### tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ae4424cc-fb3f-4171-953c-dba48175487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Features: ['abort' 'about' 'access' 'accessdate' 'account' 'acid' 'act' 'active'\n",
      " 'addison' 'additional']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform([clean_text])\n",
    "print(\"TF-IDF Features:\", tfidf_vectorizer.get_feature_names_out()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a536a7fd-078e-4d9a-9da3-9debcf622404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample words in vocabulary: ['the', 'wikipedia', 'of', 'references', 'in', 'and', 'link', 'external', 'a', 'also', 'is', 'see', 'to', 'disambiguation', 'page', 'career', 'history', 'with', 'life', 'all']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample words in vocabulary:\", list(word2vec_cbow.wv.index_to_key)[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51411f0a-b5f1-4324-b35e-3c0692552740",
   "metadata": {},
   "source": [
    "#### Word2Vec CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cd4789a8-2bce-4ef5-98f8-322110f0b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 1039\n",
      "Sample Words in Vocabulary: ['the', 'wikipedia', 'of', 'references', 'in', 'and', 'link', 'external', 'a', 'also']\n",
      "Similar Words: [('trials', 0.3639206290245056), ('space', 0.32055142521858215), ('mathematical', 0.25173982977867126), ('first', 0.25064992904663086), ('stadium', 0.24792534112930298)]\n"
     ]
    }
   ],
   "source": [
    "word2vec_cbow = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "word2vec_cbow.save(\"word2vec_cbow.model\")\n",
    "print(\"Vocabulary Size:\", len(word2vec_cbow.wv))\n",
    "print(\"Sample Words in Vocabulary:\", list(word2vec_cbow.wv.index_to_key)[:10])\n",
    "word_to_check = \"wikipedia\"  # Choose a valid word from vocabulary\n",
    "if word_to_check in word2vec_cbow.wv:\n",
    "    print(\"Similar Words:\", word2vec_cbow.wv.most_similar(word_to_check, topn=5))\n",
    "else:\n",
    "    print(f\"'{word_to_check}' not found in vocabulary. Try another word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1155c-06f7-4615-b9d1-940e14664dcc",
   "metadata": {},
   "source": [
    "#### Word2Vec Skip-gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4182a9fc-32fc-4a25-b028-a382c8017c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-gram Vocabulary Size: 1039\n",
      "Skip-gram Sample Words: ['the', 'wikipedia', 'of', 'references', 'in', 'and', 'link', 'external', 'a', 'also']\n",
      "Skip-gram Similar Words: [('the', 0.9531342387199402), ('and', 0.9510596990585327), ('references', 0.9473447799682617), ('a', 0.9407880902290344), ('in', 0.9359356164932251)]\n"
     ]
    }
   ],
   "source": [
    "word2vec_sg = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "word2vec_sg.save(\"word2vec_skipgram.model\")\n",
    "print(\"Skip-gram Vocabulary Size:\", len(word2vec_sg.wv))\n",
    "print(\"Skip-gram Sample Words:\", list(word2vec_sg.wv.index_to_key)[:10])\n",
    "if \"wikipedia\" in word2vec_sg.wv:\n",
    "    print(\"Skip-gram Similar Words:\", word2vec_sg.wv.most_similar(\"wikipedia\", topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd63e33-b298-471e-8bbf-a9a27c6edf0f",
   "metadata": {},
   "source": [
    "#### FastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8e95b082-104e-480c-8626-298b8cf18f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText Vocabulary Size: 1039\n",
      "FastText Sample Words: ['the', 'wikipedia', 'of', 'references', 'in', 'and', 'link', 'external', 'a', 'also']\n",
      "FastText Similar Words: [('nation', 0.6517307162284851), ('national', 0.6498042941093445), ('station', 0.6383634209632874), ('relation', 0.6306263208389282), ('international', 0.6161552667617798)]\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = FastText(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "fasttext_model.save(\"fasttext.model\")\n",
    "print(\"FastText Vocabulary Size:\", len(fasttext_model.wv))\n",
    "print(\"FastText Sample Words:\", list(fasttext_model.wv.index_to_key)[:10])\n",
    "if \"wikipedia\" in fasttext_model.wv:\n",
    "    print(\"FastText Similar Words:\", fasttext_model.wv.most_similar(\"wikipedia\", topn=5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
